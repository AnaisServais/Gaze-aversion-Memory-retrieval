{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae52d9c-ab25-4bef-a17f-fa3655f62780",
   "metadata": {},
   "source": [
    "# Code to reproduce statistical tests and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cbfb87-7a22-4e67-a08d-98b72025d4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anais\\AppData\\Roaming\\Python\\Python37\\site-packages\\outdated\\utils.py:18: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.0, the latest is 0.5.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "import scikit_posthocs\n",
    "import scipy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafced28-a98c-4484-8e4b-f8d681762779",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_WD = os.getcwd() # get current work directory\n",
    "# path were we store data files ready for statistical analyses (done in figures_gaze_aversions.ipynb)*\n",
    "files_for_stats = set_WD + r'\\data\\processed_data\\files for statitical analyses\\\\'\n",
    "path_for_figures = set_WD + r'\\data\\figures\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02902a52-07b2-4033-9c52-b83954bb4644",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistical analyses for gaze aversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb5ae45-9e14-49ff-b2af-6fbd9833988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the different files containing data that we want to compare\n",
    "# these dataframe contain 3 column\n",
    "# sujet = code of the participant (ex : P01)\n",
    "# effort OR clarte = the name of the variable with 3 levels (1, 2, or 3)\n",
    "# prop_VD = the proportion of questions where gaze aversion was observed (VD stands for visual disengagement = gaze aversion)\n",
    "\n",
    "VD_access_clarte = pd.read_csv(files_for_stats + \"Access_prop_VD_clarte.csv\") \n",
    "VD_access_effort = pd.read_csv(files_for_stats + \"Access_prop_VD_effort .csv\")\n",
    "VD_visu_clarte = pd.read_csv(files_for_stats + \"Elaboration_prop_VD_clarte.csv\")\n",
    "VD_visu_effort = pd.read_csv(files_for_stats + \"Elaboration_prop_VD_effort .csv\")\n",
    "# correct a typo existing in column name\n",
    "VD_access_effort= VD_access_effort.rename(columns={'effort ': 'effort'})\n",
    "VD_visu_effort = VD_visu_effort.rename(columns={'effort ': 'effort'})\n",
    "\n",
    "df = pd.read_csv(set_WD+ r\"\\data\\processed_data\\data_T1_access.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f17473-1c01-4ecf-9338-8e5d69c4c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_sujets_anon=['P01','P02','P03','P04','P05', \\\n",
    "     'P06','P07','P09','P10', 'P11', \\\n",
    "     'P12','P13','P14','P15','P16', \\\n",
    "     'P17','P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', \\\n",
    "     'P28', 'P29', 'P30', 'P31', 'P32', 'P33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e43a5f-76bd-4d6b-8061-f93f97008d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_Friedman_test(file, var, period, liste_sujets):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Define a function to run Friedman test\n",
    "    \n",
    "    Args : \n",
    "        var : Compare the percentage of questions with gaze aversion depending on the 3 levels of either effort or vividness \n",
    "        period : (either during access or elaboration phase)\n",
    "        file : name of the df containing the data of the var and period concerned\n",
    "        liste_sujets : liste_sujets_anon (i.e. the list of all the anonymized code for participants)\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    for s in liste_sujets:\n",
    "        \n",
    "        if list(file['sujet']).count(s) < 3:\n",
    "            sub_df = file[file['sujet'] == s]\n",
    "            if 1 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(1), 0] # ATTENTION forced to put 0 for NaN values\n",
    "            if 2 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(2), 0]\n",
    "            if 3 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(3), 0]\n",
    "            \n",
    "    #perform the Friedman test\n",
    "    print('\\033[1m' + period, var, '\\033[0m' + \" \")\n",
    "    print(pg.friedman(data=file,dv='prop_VD',within=var,subject='sujet',method='f'))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7badcdad-2ecd-43e6-bf94-74f4585d0612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1maccess clarte \u001b[0m \n",
      "          Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  clarte  0.214912  1.9375  60.0625  8.486034  0.000644\n",
      " \n",
      "\u001b[1maccess effort \u001b[0m \n",
      "          Source         W   ddof1    ddof2          F         p-unc\n",
      "Friedman  effort  0.457705  1.9375  60.0625  26.164431  9.425314e-09\n",
      " \n",
      "\u001b[1melaboration clarte \u001b[0m \n",
      "          Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  clarte  0.158405  1.9375  60.0625  5.834827  0.005238\n",
      " \n",
      "\u001b[1melaboration effort \u001b[0m \n",
      "          Source         W   ddof1    ddof2        F    p-unc\n",
      "Friedman  effort  0.042763  1.9375  60.0625  1.38488  0.25807\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_Friedman_test(VD_access_clarte, 'clarte', 'access', liste_sujets_anon)\n",
    "run_Friedman_test(VD_access_effort, 'effort', 'access', liste_sujets_anon)\n",
    "\n",
    "run_Friedman_test(VD_visu_clarte, 'clarte', 'elaboration', liste_sujets_anon)\n",
    "run_Friedman_test(VD_visu_effort, 'effort', 'elaboration', liste_sujets_anon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9476432f-76aa-43fb-8f8d-aab4bc015073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Nemenyi_posthocs(file, var, period, liste_sujets):\n",
    "    '''\n",
    "    Define a function to run Nemenyi posthocs tests\n",
    "    Args : \n",
    "        var : Compare the percentage of questions with gaze aversion depending on the 3 levels of either effort or vividness \n",
    "        period : type of period (either during access or elaboration phase)\n",
    "        file : name of the df containing the data of the var and period concerned\n",
    "        liste_sujets : liste_sujets_anon (i.e. the list of all the anonymized code for participants)\n",
    "\n",
    "   '''\n",
    "    \n",
    "    \n",
    "    for s in liste_sujets:\n",
    "        \n",
    "        if list(file['sujet']).count(s) < 3:\n",
    "            sub_df = file[file['sujet'] == s]\n",
    "            if 1 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(1), 0] # ATTENTION forced to put 0 for NaN values\n",
    "            if 2 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(2), 0]\n",
    "            if 3 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(3), 0]\n",
    "            \n",
    "    #perform the Nemenyi posthocs test\n",
    "    print('\\033[1m' + period, var, '\\033[0m' + \" \")\n",
    "    print(scikit_posthocs.posthoc_nemenyi_friedman(file,y_col='prop_VD',block_col='sujet', group_col=var, melted=True))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19678e62-5110-4396-ba96-e0525df5693a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1maccess clarte \u001b[0m \n",
      "          1         2         3\n",
      "1  1.000000  0.001353  0.186906\n",
      "2  0.001353  1.000000  0.186906\n",
      "3  0.186906  0.186906  1.000000\n",
      " \n",
      "\u001b[1maccess effort \u001b[0m \n",
      "       1         2         3\n",
      "1  1.000  0.001000  0.001000\n",
      "2  0.001  1.000000  0.678721\n",
      "3  0.001  0.678721  1.000000\n",
      " \n",
      "\u001b[1melaboration clarte \u001b[0m \n",
      "          1         2         3\n",
      "1  1.000000  0.023554  0.023554\n",
      "2  0.023554  1.000000  0.900000\n",
      "3  0.023554  0.900000  1.000000\n",
      " \n",
      "\u001b[1melaboration effort \u001b[0m \n",
      "          1         2         3\n",
      "1  1.000000  0.499954  0.291414\n",
      "2  0.499954  1.000000  0.900000\n",
      "3  0.291414  0.900000  1.000000\n",
      " \n"
     ]
    }
   ],
   "source": [
    "run_Nemenyi_posthocs(VD_access_clarte, 'clarte', 'access', liste_sujets_anon)\n",
    "run_Nemenyi_posthocs(VD_access_effort, 'effort', 'access', liste_sujets_anon)\n",
    "\n",
    "run_Nemenyi_posthocs(VD_visu_clarte, 'clarte', 'elaboration', liste_sujets_anon)\n",
    "run_Nemenyi_posthocs(VD_visu_effort, 'effort', 'elaboration', liste_sujets_anon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecc4793-503b-494d-b6c3-387edf49653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_suj = []\n",
    "list_eff = []\n",
    "list_clarte = []\n",
    "list_median_quality = []\n",
    "list_mean_quality = []\n",
    "list_gaze_aversion = []\n",
    "\n",
    "for suj in liste_sujets_anon:\n",
    "    df_suj = df[df['Sujet'] == suj]\n",
    "    df_suj_no_av = df_suj[df_suj['VD_here'] == 0] # without aversions\n",
    "    df_suj = df_suj[df_suj['VD_here'] != 0] # with aversions \n",
    "    \n",
    "    \n",
    "    df_effort1 = df_suj[df_suj['effort '] == 1]\n",
    "    df_effort2 = df_suj[df_suj['effort '] == 2]\n",
    "    df_effort3 = df_suj[df_suj['effort '] == 3]\n",
    "    \n",
    "    df_effort1_no_av = df_suj_no_av[df_suj_no_av['effort '] == 1]\n",
    "    df_effort2_no_av = df_suj_no_av[df_suj_no_av['effort '] == 2]\n",
    "    df_effort3_no_av = df_suj_no_av[df_suj_no_av['effort '] == 3]\n",
    "       \n",
    "    if len(df_effort1) > 0 :\n",
    "        df_effort1_clarte1 = df_effort1[df_effort1['clarte'] == 1]\n",
    "        df_effort1_clarte2 = df_effort1[df_effort1['clarte'] == 2]\n",
    "        df_effort1_clarte3 = df_effort1[df_effort1['clarte'] == 3]\n",
    "        \n",
    "        df_effort1_clarte1 = df_effort1_clarte1.reset_index()\n",
    "        df_effort1_clarte2 = df_effort1_clarte2.reset_index()\n",
    "        df_effort1_clarte3 = df_effort1_clarte3.reset_index()\n",
    "        \n",
    "        \n",
    "        if len(df_effort1_clarte1) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort1_clarte1['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte1['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort1_clarte1) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort1_clarte2) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort1_clarte2['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte2['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort1_clarte2) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort1_clarte3) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort1_clarte3['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte3['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort1_clarte3) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "    elif len(df_effort1) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        \n",
    "    if len(df_effort2) > 0 :\n",
    "        df_effort2_clarte1 = df_effort2[df_effort2['clarte'] == 1]\n",
    "        df_effort2_clarte2 = df_effort2[df_effort2['clarte'] == 2]\n",
    "        df_effort2_clarte3 = df_effort2[df_effort2['clarte'] == 3]\n",
    "        \n",
    "        df_effort2_clarte1 = df_effort2_clarte1.reset_index()\n",
    "        df_effort2_clarte2 = df_effort2_clarte2.reset_index()\n",
    "        df_effort2_clarte3 = df_effort2_clarte3.reset_index()\n",
    "        \n",
    "        if len(df_effort2_clarte1) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort2_clarte1['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte1['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort2_clarte1) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort2_clarte2) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort2_clarte2['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte2['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort2_clarte2) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort2_clarte3) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort2_clarte3['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte3['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort2_clarte3) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "    elif len(df_effort2) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "            \n",
    "    if len(df_effort3) > 0 :\n",
    "        df_effort3_clarte1 = df_effort3[df_effort3['clarte'] == 1]\n",
    "        df_effort3_clarte2 = df_effort3[df_effort3['clarte'] == 2]\n",
    "        df_effort3_clarte3 = df_effort3[df_effort3['clarte'] == 3]\n",
    "        \n",
    "        df_effort3_clarte1 = df_effort3_clarte1.reset_index()\n",
    "        df_effort3_clarte2 = df_effort3_clarte2.reset_index()\n",
    "        df_effort3_clarte3 = df_effort3_clarte3.reset_index()\n",
    "        \n",
    "        if len(df_effort3_clarte1) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort3_clarte1['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte1['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort3_clarte1) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort3_clarte2) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort3_clarte2['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte2['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort3_clarte2) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort3_clarte3) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort3_clarte3['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte3['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(1)\n",
    "        if len(df_effort3_clarte3) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(1)\n",
    "    elif len(df_effort3) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(1)\n",
    "            \n",
    "    if len(df_effort1_no_av) > 0 :\n",
    "        \n",
    "        df_effort1_clarte1_no_av = df_effort1_no_av[df_effort1_no_av['clarte'] == 1]\n",
    "        df_effort1_clarte2_no_av = df_effort1_no_av[df_effort1_no_av['clarte'] == 2]\n",
    "        df_effort1_clarte3_no_av = df_effort1_no_av[df_effort1_no_av['clarte'] == 3]\n",
    "        \n",
    "        df_effort1_clarte1_no_av = df_effort1_clarte1_no_av.reset_index()\n",
    "        df_effort1_clarte2_no_av = df_effort1_clarte2_no_av.reset_index()\n",
    "        df_effort1_clarte3_no_av = df_effort1_clarte3_no_av.reset_index()\n",
    "        \n",
    "        if len(df_effort1_clarte1_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort1_clarte1_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte1_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort1_clarte1_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort1_clarte2_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort1_clarte2_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte2_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort1_clarte2_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort1_clarte3_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort1_clarte3_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort1_clarte3_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort1_clarte3_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(1)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "    elif len(df_effort1_no_av) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(1)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        \n",
    "    if len(df_effort2_no_av) > 0 :\n",
    "        df_effort2_clarte1_no_av = df_effort2_no_av[df_effort2_no_av['clarte'] == 1]\n",
    "        df_effort2_clarte2_no_av = df_effort2_no_av[df_effort2_no_av['clarte'] == 2]\n",
    "        df_effort2_clarte3_no_av = df_effort2_no_av[df_effort2_no_av['clarte'] == 3]\n",
    "        \n",
    "        df_effort2_clarte1_no_av = df_effort2_clarte1_no_av.reset_index()\n",
    "        df_effort2_clarte2_no_av = df_effort2_clarte2_no_av.reset_index()\n",
    "        df_effort2_clarte3_no_av = df_effort2_clarte3_no_av.reset_index()\n",
    "        \n",
    "        if len(df_effort2_clarte1_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort2_clarte1_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte1_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort2_clarte1_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort2_clarte2_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort2_clarte2_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte2_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort2_clarte2_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort2_clarte3_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort2_clarte3_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort2_clarte3_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort2_clarte3_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(2)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "    elif len(df_effort2_no_av) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(2)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "            \n",
    "    if len(df_effort3_no_av) > 0 :\n",
    "        df_effort3_clarte1_no_av = df_effort3_no_av[df_effort3_no_av['clarte'] == 1]\n",
    "        df_effort3_clarte2_no_av = df_effort3_no_av[df_effort3_no_av['clarte'] == 2]\n",
    "        df_effort3_clarte3_no_av = df_effort3_no_av[df_effort3_no_av['clarte'] == 3]\n",
    "        \n",
    "        df_effort3_clarte1_no_av = df_effort3_clarte1_no_av.reset_index()\n",
    "        df_effort3_clarte2_no_av = df_effort3_clarte2_no_av.reset_index()\n",
    "        df_effort3_clarte3_no_av = df_effort3_clarte3_no_av.reset_index()\n",
    "        \n",
    "        if len(df_effort3_clarte1_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(df_effort3_clarte1_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte1_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort3_clarte1_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(1)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort3_clarte2_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(df_effort3_clarte2_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte2_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort3_clarte2_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(2)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort3_clarte3_no_av) > 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(df_effort3_clarte3_no_av['Etape_2'].median())\n",
    "            list_mean_quality.append(df_effort3_clarte3_no_av['Etape_2'].mean())\n",
    "            list_gaze_aversion.append(0)\n",
    "        if len(df_effort3_clarte3_no_av) == 0:\n",
    "            list_suj.append(suj)\n",
    "            list_eff.append(3)\n",
    "            list_clarte.append(3)\n",
    "            list_median_quality.append(np.nan)\n",
    "            list_mean_quality.append(np.nan)\n",
    "            list_gaze_aversion.append(0)\n",
    "    elif len(df_effort3_no_av) == 0: \n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(1)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(2)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)\n",
    "        list_suj.append(suj)\n",
    "        list_eff.append(3)\n",
    "        list_clarte.append(3)\n",
    "        list_median_quality.append(np.nan)\n",
    "        list_mean_quality.append(np.nan)\n",
    "        list_gaze_aversion.append(0)          \n",
    "    \n",
    "        \n",
    "\n",
    "            \n",
    "df_interaction_quality = pd.DataFrame({'Sujet':list_suj, 'aversion': list_gaze_aversion, 'effort': list_eff, 'clarte':list_clarte, \\\n",
    "                                      'median_quality':list_median_quality, 'mean_quality': list_mean_quality})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96890b74-403d-4ee5-b44a-85f4317cc9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.715404552742884\n",
      "0.9372968608612495\n"
     ]
    }
   ],
   "source": [
    "# Calculate average and std quality of memories for all trials \n",
    "list_av_quality = []\n",
    "for suj in liste_sujets_anon:\n",
    "    df_suj = df[df['Sujet'] == suj]\n",
    "    av_suj = df_suj['Etape_2'].mean()\n",
    "    list_av_quality.append(av_suj)\n",
    "print(\"Mean : \",np.mean(list_av_quality))\n",
    "print(\"STD : \",np.std(list_av_quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ecdf84-6a5f-424f-8ca7-333d6b6af7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W-val</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wilcoxon</th>\n",
       "      <td>211.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.665789</td>\n",
       "      <td>0.092473</td>\n",
       "      <td>0.523889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          W-val alternative     p-val       RBC      CLES\n",
       "Wilcoxon  211.0   two-sided  0.665789  0.092473  0.523889"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference of quality of memories depending on the presence/absence of gaze aversion\n",
    "# Wilcoxon ranked sign test\n",
    "mean_quality_av = []\n",
    "mean_quality_no_av = []\n",
    "for suj in liste_sujets_anon:\n",
    "    df_suj = df_interaction_quality[df_interaction_quality['Sujet'] == suj]\n",
    "    df_av = df_suj[df_suj['aversion'] ==1]\n",
    "    df_no_av = df_suj[df_suj['aversion'] ==0]\n",
    "    mean_quality_av.append(df_av['mean_quality'].mean())\n",
    "    mean_quality_no_av.append(df_no_av['mean_quality'].mean())\n",
    "scipy.stats.wilcoxon(mean_quality_av, mean_quality_no_av)\n",
    "pg.wilcoxon(mean_quality_av, mean_quality_no_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d8fc8d-aa5e-41d0-aca4-63e641099b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of participants 30\n",
      "18 with better quality during aversion than without aversion\n",
      "60.0 %\n"
     ]
    }
   ],
   "source": [
    "# count number and % of participants were number of details is higher when there is a gaze aversion\n",
    "col_av = []\n",
    "for i in range(len(mean_quality_av)):\n",
    "    col_av.append(1)\n",
    "for i in range(len(mean_quality_no_av)):\n",
    "    col_av.append(0)\n",
    "\n",
    "count_with_av = 0 # participants doing at least one gaze aversion\n",
    "diff_qual_av = [] \n",
    "for el in range(len(mean_quality_av)):\n",
    "    if math.isnan(mean_quality_av[el]) == False:\n",
    "        diff_qual_av.append(mean_quality_av[el]-mean_quality_no_av[el])\n",
    "        count_with_av = count_with_av + 1\n",
    "print('number of participants', count_with_av)\n",
    "count = 0\n",
    "for i in diff_qual_av:\n",
    "    if i > 0:\n",
    "        count = count + 1\n",
    "print(count, 'with better quality during aversion than without aversion')\n",
    "print(count/count_with_av*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20647c1-fbb2-4d20-a3cf-3fc17d6f1673",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistical analyses for eye vergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f969c563-11d0-4b57-b791-ff6edee8560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files for access period\n",
    "vergence_file_access = pd.read_csv(set_WD+r\"\\data\\processed_data\\eye vergence\\vergence_access.csv\")\n",
    "data_T1_access = pd.read_csv(set_WD+r\"\\data\\processed_data\\data_T1_access.csv\")\n",
    "# files for elaboration period\n",
    "vergence_file_visu = pd.read_csv(set_WD+r\"\\data\\processed_data\\eye vergence\\\\vergence_visu.csv\")\n",
    "data_T1_visu = pd.read_csv(set_WD+r\"\\data\\processed_data\\data_T1_visu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b57ee2-6933-40dd-8774-a5fbb184289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_access_clarte = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"conv_Access_clarte.csv\")\n",
    "conv_access_effort = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"conv_Access_effort.csv\")\n",
    "conv_visu_clarte = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"conv_Visu_clarte.csv\")\n",
    "conv_visu_effort = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"conv_Visu_effort.csv\")\n",
    "\n",
    "\n",
    "div_access_clarte = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"div_Access_clarte.csv\")\n",
    "div_access_effort = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"div_Access_effort.csv\")\n",
    "div_visu_clarte = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"div_Visu_clarte.csv\")\n",
    "div_visu_effort = pd.read_csv(set_WD + r'\\data\\processed_data\\eye vergence\\\\' + \"div_Visu_effort.csv\")\n",
    "\n",
    "\n",
    "conv_access_effort= conv_access_effort.rename(columns={'effort ': 'effort'})\n",
    "conv_visu_effort = conv_visu_effort.rename(columns={'effort ': 'effort'})\n",
    "div_access_effort= div_access_effort.rename(columns={'effort ': 'effort'})\n",
    "div_visu_effort = div_visu_effort.rename(columns={'effort ': 'effort'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8443c66-21f3-4f3c-9e72-d682e5bcd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values(file, var, period): # this function will fill with zéro if a participant never chose spontaneous as a level of effort for example\n",
    "    \n",
    "    liste_sujets=['P01','P02','P03','P04','P05', \\\n",
    "     'P06','P07','P09','P10', 'P11', \\\n",
    "     'P12','P13','P14','P15','P16', \\\n",
    "     'P17','P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', \\\n",
    "     'P28', 'P29', 'P30', 'P31', 'P32', 'P33']\n",
    "    \n",
    "    for s in liste_sujets:\n",
    "        if list(file['sujet']).count(s) < 3:\n",
    "            sub_df = file[file['sujet'] == s]\n",
    "            if 1 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(1), 0] # ATTENTION forced to put 0 for NaN values\n",
    "            if 2 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(2), 0]\n",
    "            if 3 not in list(sub_df[var]):\n",
    "                file.loc[len(file['sujet'])] = [len(file['sujet']), s, int(3), 0]\n",
    "\n",
    "    return file\n",
    "\n",
    "conv_access_clarte = check_values(conv_access_clarte, 'clarte', 'access')\n",
    "conv_access_effort = check_values(conv_access_effort, 'effort', 'access')\n",
    "conv_visu_clarte = check_values(conv_visu_clarte, 'clarte', 'elaboration')\n",
    "conv_visu_effort = check_values(conv_visu_effort, 'effort', 'elaboration')\n",
    "\n",
    "div_access_clarte = check_values(div_access_clarte, 'clarte', 'access')\n",
    "div_access_effort = check_values(div_access_effort, 'effort', 'access')\n",
    "div_visu_clarte = check_values(div_visu_clarte, 'clarte', 'elaboration')\n",
    "div_visu_effort = check_values(div_visu_effort, 'effort', 'elaboration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bffd052-0ac0-4649-89c2-449003e9b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence, Access, clarte \n",
      "           Source        W   ddof1    ddof2         F     p-unc\n",
      "Friedman  clarte  0.23207  1.9375  60.0625  9.368245  0.000331 \n",
      "\n",
      "Convergence, Elaboration, clarte \n",
      "           Source         W   ddof1    ddof2          F    p-unc\n",
      "Friedman  clarte  0.267551  1.9375  60.0625  11.323787  0.00008 \n",
      "\n",
      "Convergence, Access, effort\n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  effort  0.106557  1.9375  60.0625  3.697248  0.031863 \n",
      "\n",
      "Convergence, Elaboration, effort\n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  effort  0.173986  1.9375  60.0625  6.529652  0.002981 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Convergence, Access, clarte \\n', pg.friedman(data=conv_access_clarte,dv='prop_VD',within='clarte',subject='sujet',method='f'), '\\n')\n",
    "print('Convergence, Elaboration, clarte \\n', pg.friedman(data=conv_visu_clarte,dv='prop_VD',within='clarte',subject='sujet',method='f'), '\\n')\n",
    "print('Convergence, Access, effort\\n', pg.friedman(data=conv_access_effort,dv='prop_VD',within='effort',subject='sujet',method='f'), '\\n')\n",
    "print('Convergence, Elaboration, effort\\n', pg.friedman(data=conv_visu_effort,dv='prop_VD',within='effort',subject='sujet',method='f'), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b850cc-87a0-4e67-a21a-d74bf872919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergence, Access, clarte \n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  clarte  0.117578  1.9375  60.0625  4.130589  0.021895 \n",
      "\n",
      "Divergence, Elaboration, clarte \n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  clarte  0.115728  1.9375  60.0625  4.057087  0.023325 \n",
      "\n",
      "Divergence, Access, effort\n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  effort  0.102033  1.9375  60.0625  3.522432  0.037122 \n",
      "\n",
      "Divergence, Elaboration, effort\n",
      "           Source         W   ddof1    ddof2         F     p-unc\n",
      "Friedman  effort  0.230847  1.9375  60.0625  9.304063  0.000347 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Divergence, Access, clarte \\n', pg.friedman(data=div_access_clarte,dv='prop_VD',within='clarte',subject='sujet',method='f'), '\\n')\n",
    "print('Divergence, Elaboration, clarte \\n', pg.friedman(data=div_visu_clarte,dv='prop_VD',within='clarte',subject='sujet',method='f'), '\\n')\n",
    "print('Divergence, Access, effort\\n', pg.friedman(data=div_access_effort,dv='prop_VD',within='effort',subject='sujet',method='f'), '\\n')\n",
    "print('Divergence, Elaboration, effort\\n', pg.friedman(data=div_visu_effort,dv='prop_VD',within='effort',subject='sujet',method='f'), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902d407e-f811-4e1f-a19b-410a7742f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of participants 23\n",
      "9 with better quality during aversion than without divergence\n",
      "39.130434782608695 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=98.0, pvalue=0.23447084426879883)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference of quality of memories depending on the presence/absence of divergence\n",
    "# Wilcoxon ranked sign test\n",
    "mean_quality_div = []\n",
    "mean_quality_no_div = []\n",
    "for suj in liste_sujets_anon:\n",
    "    df_suj = vergence_file_access[vergence_file_access['Sujet'] == suj]\n",
    "    df_suj = df_suj[df_suj['VD_here'] == 0]\n",
    "    df_div = df_suj[df_suj['sig_vergence'] =='divergence']\n",
    "    df_no_div = df_suj[df_suj['sig_vergence'] !='divergence']\n",
    "    mean_quality_div.append(df_div['Etape_2'].mean())\n",
    "    mean_quality_no_div.append(df_no_div['Etape_2'].mean())\n",
    "\n",
    "diff_qual_div = [] \n",
    "count_with_div = 0\n",
    "for el in range(len(mean_quality_div)):\n",
    "    if math.isnan(mean_quality_div[el]) == False:\n",
    "        diff_qual_div.append(mean_quality_div[el]-mean_quality_no_div[el])\n",
    "        count_with_div = count_with_div + 1\n",
    "print('number of participants', count_with_div)\n",
    "count = 0\n",
    "for i in diff_qual_div:\n",
    "    if i > 0:\n",
    "        count = count + 1\n",
    "print(count, 'with better quality during aversion than without divergence')\n",
    "print(count/count_with_div*100, '%')\n",
    "scipy.stats.wilcoxon(diff_qual_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b52d610-5043-4097-82a5-2ce4b81af41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of participants 19\n",
      "8 with better quality during aversion than without convergence\n",
      "42.10526315789473 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=76.0, pvalue=0.4653167724609375)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference of quality of memories depending on the presence/absence of convergence\n",
    "# Wilcoxon ranked sign test\n",
    "mean_quality_conv = []\n",
    "mean_quality_no_conv = []\n",
    "\n",
    "for suj in liste_sujets_anon:\n",
    "    df_suj = vergence_file_access[vergence_file_access['Sujet'] == suj]\n",
    "    df_suj = df_suj[df_suj['VD_here'] == 0]\n",
    "    df_conv = df_suj[df_suj['sig_vergence'] =='convergence']\n",
    "    df_no_conv = df_suj[df_suj['sig_vergence'] !='convergence']\n",
    "    mean_quality_conv.append(df_conv['Etape_2'].mean())\n",
    "    mean_quality_no_conv.append(df_no_conv['Etape_2'].mean())\n",
    "\n",
    "diff_qual_conv = [] \n",
    "count_with_conv = 0\n",
    "for el in range(len(mean_quality_conv)):\n",
    "    if math.isnan(mean_quality_conv[el]) == False:\n",
    "        diff_qual_conv.append(mean_quality_conv[el]-mean_quality_no_conv[el])\n",
    "        count_with_conv = count_with_conv + 1\n",
    "print('number of participants', count_with_conv)\n",
    "count = 0\n",
    "for i in diff_qual_conv:\n",
    "    if i > 0:\n",
    "        count = count + 1\n",
    "print(count, 'with better quality during aversion than without convergence')\n",
    "print(count/count_with_conv*100, '%')\n",
    "\n",
    "scipy.stats.wilcoxon(diff_qual_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0fa61-e4d8-4547-b893-b1c1e4c281cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
